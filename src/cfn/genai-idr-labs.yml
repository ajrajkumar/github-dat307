---
AWSTemplateFormatVersion: 2010-09-09

Description: >
    This template deploys a VPC, Aurora DB Cluster, and a Amazon SageMaker Notebook Instance

Parameters:
  TemplateName:
    Type: String
    Default: genai-idr-labs
    Description: Name used for different elements created.

  VpcName:
    Default: APGPGVectorWorkshop
    Type: String

  VpcCIDR:
    Default: 10.215.0.0/16
    Type: String

  Subnet1CIDR:
    Default: 10.215.10.0/24
    Type: String

  Subnet2CIDR:
    Default: 10.215.20.0/24
    Type: String

  Subnet3CIDR:
    Default: 10.215.30.0/24
    Type: String

  Subnet4CIDR:
    Default: 10.215.40.0/24
    Type: String

  DefaultCodeRepository:
    Default: https://github.com/aws-samples/aurora-postgresql-pgvector.git
    Type: String

  DBEngineVersion:
    Type: String
    Default: 15.6
    AllowedValues:
      - 15.6
  
  DBInstanceSize:
    Type: String
    Default: db.r6gd.2xlarge
    AllowedValues:
      - db.r6g.xlarge
      - db.r6g.2xlarge
      - db.r6gd.2xlarge
      - db.r6g.4xlarge
      - db.r6gd.4xlarge

  DBPort:
    Description: TCP/IP Port for the Database Instance
    Type: Number
    Default: 5432
    ConstraintDescription: 'Must be in the range [1150-65535]'
    MinValue: 1150
    MaxValue: 65535

  IsWorkshopStudioEnv:
    Type: String
    Default: "no"
    AllowedValues:
      - "no"
      - "yes"
    Description: Whether this stack is being deployed in a Workshop Studio environment or not. If not sure, leave as default of "no".

  ParticipantRoleArn:
    Type: String
    Description: Workshop studio magic variable ParticipantRoleArn

  AssetsBucketName:
    Type: String
    Description: Workshop studio magic variable AssetsBucketName
    
  AssetsBucketPrefix:
    Type: String
    Description: Workshop studio magic variable AssetsBucketPrefix    

  AmiID:
    Type: AWS::SSM::Parameter::Value<AWS::EC2::Image::Id>
    Description: "The ID of the AMI."
    Default: /aws/service/ami-amazon-linux-latest/al2023-ami-kernel-default-x86_64

  Psycopg2LambdaLayerName:
    Description: >
      Psycopg2 Layer Name and version
    Type: String
    Default: "psycopg2-layer:1"

## Conditions
Conditions:
  isInWS:
    !Equals [ !Ref IsWorkshopStudioEnv, "yes" ]
  isNotInWS:
    !Equals [ !Ref IsWorkshopStudioEnv, "no" ]    

  isWorkshopStudio: !Equals [ !Ref IsWorkshopStudioEnv, "yes"]

Resources:
## Create enhanced monitoring role
  roleEnhancedMonitoring:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub ${AWS::StackName}-monitor-${AWS::Region}
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - sts:AssumeRole
            Principal:
              Service:
                - monitoring.rds.amazonaws.com
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole

# VPC ----------------------------------------------------------
  VPC:
    Type: AWS::EC2::VPC
    Properties:
      CidrBlock: !Ref VpcCIDR
      EnableDnsHostnames: true
      EnableDnsSupport: true
      Tags:
        - Key: Name
          Value: !Ref VpcName

  InternetGateway:
    Type: AWS::EC2::InternetGateway
    Properties:
      Tags:
        - Key: Name
          Value: !Ref VpcName

  InternetGatewayAttachment:
    Type: AWS::EC2::VPCGatewayAttachment
    Properties:
      InternetGatewayId: !Ref InternetGateway
      VpcId: !Ref VPC

  Subnet1:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      AvailabilityZone: !Select [ 0, !GetAZs ]
      MapPublicIpOnLaunch: true
      CidrBlock: !Ref Subnet1CIDR
      Tags:
        - Key: Name
          Value: !Sub ${VpcName} (Public)

  Subnet2:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      AvailabilityZone: !Select [ 1, !GetAZs ]
      MapPublicIpOnLaunch: true
      CidrBlock: !Ref Subnet2CIDR
      Tags:
        - Key: Name
          Value: !Sub ${VpcName} (Public)

  Subnet3:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      AvailabilityZone: !Select [ 0, !GetAZs ]
      MapPublicIpOnLaunch: false
      CidrBlock: !Ref Subnet3CIDR
      Tags:
        - Key: Name
          Value: !Sub ${VpcName} (Private)

  Subnet4:
    Type: AWS::EC2::Subnet
    Properties:
      VpcId: !Ref VPC
      AvailabilityZone: !Select [ 1, !GetAZs ]
      MapPublicIpOnLaunch: false
      CidrBlock: !Ref Subnet4CIDR
      Tags:
        - Key: Name
          Value: !Sub ${VpcName} (Private)

  RouteTable:
    Type: AWS::EC2::RouteTable
    Properties:
      VpcId: !Ref VPC
      Tags:
        - Key: Name
          Value: !Ref VpcName

  DefaultRoute:
    Type: AWS::EC2::Route
    Properties:
      RouteTableId: !Ref RouteTable
      DestinationCidrBlock: 0.0.0.0/0
      GatewayId: !Ref InternetGateway

  Subnet1RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref RouteTable
      SubnetId: !Ref Subnet1

  Subnet2RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref RouteTable
      SubnetId: !Ref Subnet2

  Subnet3RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref RouteTable
      SubnetId: !Ref Subnet3

  Subnet4RouteTableAssociation:
    Type: AWS::EC2::SubnetRouteTableAssociation
    Properties:
      RouteTableId: !Ref RouteTable
      SubnetId: !Ref Subnet4

# END VPC ------------------------------------------------------


# NOTEBOOK -----------------------------------------------------
  NotebookInstance:
    Type: AWS::SageMaker::NotebookInstance
    Properties:
      InstanceType: "ml.c5.2xlarge"
      RoleArn: !GetAtt ExecutionRole.Arn
      SubnetId: !Ref Subnet1
      SecurityGroupIds:
        - !Ref SecurityGroup
      DefaultCodeRepository: !Ref DefaultCodeRepository
      VolumeSizeInGB: 50
  
  SecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Properties:
      GroupDescription: Notebook Instance Security Group
      VpcId: !Ref VPC
      SecurityGroupEgress:
        - IpProtocol: "-1"
          CidrIp: 0.0.0.0/0
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: !Ref DBPort
          ToPort: !Ref DBPort
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: 0.0.0.0/0

  ExecutionRole: 
    Type: AWS::IAM::Role
    Properties: 
      AssumeRolePolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - 
            Effect: "Allow"
            Principal: 
              Service: 
                - "sagemaker.amazonaws.com"
            Action: 
              - "sts:AssumeRole"
      Path: "/"
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSageMakerFullAccess
        - arn:aws:iam::aws:policy/SecretsManagerReadWrite
        - arn:aws:iam::aws:policy/AmazonRDSReadOnlyAccess
        - arn:aws:iam::aws:policy/AmazonBedrockFullAccess
      Policies:
        - 
          PolicyName: "s3_access"
          PolicyDocument: 
            Version: "2012-10-17"
            Statement: 
              - 
                Effect: "Allow"
                Action: 
                  - "s3:PutBucketPolicy"
                  - "s3:DeleteBucket"
                Resource: "arn:aws:s3:::sagemaker-*"                

# END NOTEBOOK -------------------------------------------------

# RDS IAM Role for Amazon Bedrock ------------------------------

  AuroraBedrockRole: 
    Type: AWS::IAM::Role
    Properties: 
      RoleName: 'Aurora-Bedrock-Role'
      AssumeRolePolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - 
            Effect: "Allow"
            Principal: 
              Service: 
                - "rds.amazonaws.com"
            Action: 
              - "sts:AssumeRole"
      Path: "/"
      Policies:
        - 
          PolicyName: 'Aurora-Bedrock-Policy'
          PolicyDocument: 
            Version: "2012-10-17"
            Statement: 
              - 
                Effect: "Allow"
                Action: 
                  - "bedrock:InvokeModel"
                Resource: [ !Sub "arn:aws:bedrock:*:${AWS::AccountId}:provisioned-model/*" , "arn:aws:bedrock:*::foundation-model/*" ]

# END RDS IAM Role for Amazon Bedrock ------------------------------

# Aurora PostgreSQL -----------------------------------------------

  EncryptionKey:
    DeletionPolicy: Retain
    UpdateReplacePolicy: Retain
    Type: AWS::KMS::Key
    Properties:
      EnableKeyRotation: true
      KeyPolicy:
        Version: 2012-10-17
        Id: !Ref AWS::StackName
        Statement:
          - Effect: Allow
            Principal:
              AWS:
                - !Sub "arn:aws:iam::${AWS::AccountId}:root"
            Action: "kms:*"
            Resource: "*"
      Tags:
        - Key: Name
          Value: !Ref AWS::StackName

  EncryptionKeyAlias:
    Type: AWS::KMS::Alias
    Properties:
      AliasName: !Sub "alias/${AWS::StackName}"
      TargetKeyId: !Ref EncryptionKey

  DBSubnetGroup:
    Type: AWS::RDS::DBSubnetGroup
    Properties:
      DBSubnetGroupDescription: "RDS DB Subnet Group"
      SubnetIds: [!Ref Subnet3, !Ref Subnet4 ]

  ## Create parameter groups for DB cluster
  apgcustomclusterparamgroup:
    Type: AWS::RDS::DBClusterParameterGroup
    Properties:
      Description: "Aurora PostgreSQL Custom Cluster parameter group"
      Family: aurora-postgresql15
      Parameters:
        shared_preload_libraries: "pg_stat_statements"
      Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName}-clusterparamgroup"
  
  ## Create parameter groups for cluster nodes
  apgcustomdbparamgroup:
    Type: AWS::RDS::DBParameterGroup
    Properties:
      Description: !Sub ${AWS::StackName}-dbparamgroup
      Family: aurora-postgresql15
      Parameters:
        log_rotation_age: '1440'
        log_rotation_size: '102400'
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-dbparamgroup

  RDSSecrets:
    Type: AWS::SecretsManager::Secret
    Properties:
      Name: "apgpg-pgvector-secret"
      Description: 'This is the secret for Aurora cluster'
      GenerateSecretString:
        SecretStringTemplate: '{"username": "postgres", "database": "postgres" }'
        GenerateStringKey: 'password'
        PasswordLength: 16
        ExcludePunctuation: true

  RDSSecrets1:
    Type: AWS::SecretsManager::Secret
    Properties:
      Name: "rdspg-pgvector-secret"
      Description: 'This is the secret for RDS PostgreSQL cluster'
      GenerateSecretString:
        SecretStringTemplate: '{"username": "postgres" }'
        GenerateStringKey: 'password'
        PasswordLength: 16
        ExcludePunctuation: true

  SecretsManagerVPCEndpoint:
    Type: 'AWS::EC2::VPCEndpoint'
    Properties:
      VpcEndpointType: 'Interface'
      PrivateDnsEnabled: true
      VpcId: !Ref VPC
      SubnetIds:
        - !Ref Subnet3
        - !Ref Subnet4
      SecurityGroupIds:
        - !GetAtt VPCSecurityGroup.GroupId
        - !GetAtt EC2SecurityGroup.GroupId
      ServiceName: !Join
        - ''
        - - com.amazonaws.
          - !Ref 'AWS::Region'
          - .secretsmanager

  VPCSecurityGroup:
    Type: 'AWS::EC2::SecurityGroup'
    Properties:
      GroupDescription: !Ref 'AWS::StackName'
      SecurityGroupEgress:
      - IpProtocol: -1
        CidrIp: "0.0.0.0/0"
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: !Ref DBPort
        ToPort: !Ref DBPort
        CidrIp: !Ref VpcCIDR
        Description: 'Access to AppServer Host Security Group'
      VpcId: !Ref VPC
      Tags:
      - Key: Name
        Value: !Sub '${AWS::StackName}-DBSecurityGroup'

## Create Aurora cluster
  DBCluster:
    Type: AWS::RDS::DBCluster
    Properties:
      DBClusterIdentifier: "apgpg-pgvector"
      Engine: aurora-postgresql
      Port: !Ref DBPort
      MasterUsername: !Join ['', ['{{resolve:secretsmanager:', !Ref RDSSecrets, ':SecretString:username}}' ]]
      MasterUserPassword: !Join ['', ['{{resolve:secretsmanager:', !Ref RDSSecrets, ':SecretString:password}}' ]]
      DBClusterParameterGroupName: !Ref apgcustomclusterparamgroup
      DBSubnetGroupName: !Ref DBSubnetGroup
      AutoMinorVersionUpgrade: true
      EnableHttpEndpoint: true
      EngineVersion: "15.6"
      KmsKeyId: !Ref EncryptionKey
      StorageEncrypted: true
      StorageType: aurora-iopt1
      BackupRetentionPeriod: 7
      DeletionProtection: false
      VpcSecurityGroupIds: [ !Ref VPCSecurityGroup ]
      Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName}"

## Deploy the first cluster node (always the writer)
  DBNodeWriter:
    Type: AWS::RDS::DBInstance
    DependsOn: DBCluster
    Properties:
      DBClusterIdentifier: !Ref DBCluster
      DBInstanceIdentifier: !Sub ${AWS::StackName}-node-01
      CopyTagsToSnapshot: true
      DBInstanceClass: !Ref DBInstanceSize
      DBParameterGroupName: !Ref apgcustomdbparamgroup
      Engine: aurora-postgresql
      MonitoringInterval: 1
      MonitoringRoleArn: !GetAtt roleEnhancedMonitoring.Arn
      PubliclyAccessible: true
      EnablePerformanceInsights: true
      PerformanceInsightsRetentionPeriod: 7
      AutoMinorVersionUpgrade: false
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-node-01

## Deploy the reader node  
  DBNodeReader:
    Type: AWS::RDS::DBInstance
    DependsOn: DBNodeWriter
    Properties:
      DBClusterIdentifier: !Ref DBCluster
      DBInstanceIdentifier: !Sub ${AWS::StackName}-node-02
      CopyTagsToSnapshot: true
      DBInstanceClass: !Ref DBInstanceSize
      DBParameterGroupName: !Ref apgcustomdbparamgroup
      Engine: aurora-postgresql
      MonitoringInterval: 1
      MonitoringRoleArn: !GetAtt roleEnhancedMonitoring.Arn
      PubliclyAccessible: true
      EnablePerformanceInsights: true
      PerformanceInsightsRetentionPeriod: 7
      AutoMinorVersionUpgrade: false
      Tags:
        - Key: Name
          Value: !Sub ${AWS::StackName}-node-02

  SecretPostgreSQLAttachment:
    Type: AWS::SecretsManager::SecretTargetAttachment
    Properties:
      SecretId: !Ref RDSSecrets
      TargetId: !Ref DBCluster
      TargetType: AWS::RDS::DBCluster

  DBInstance1:
    Type: AWS::RDS::DBInstance
    DeletionPolicy: Delete
    UpdateReplacePolicy: Delete
    Properties:
      DBInstanceIdentifier: "rdspg1"
      AllocatedStorage: "100"
      DBInstanceClass: db.t3.large
      Engine: postgres
      DBName: postgres
      MasterUsername: !Join ['', ['{{resolve:secretsmanager:', !Ref RDSSecrets1, ':SecretString:username}}' ]]
      MasterUserPassword: !Join ['', ['{{resolve:secretsmanager:', !Ref RDSSecrets1, ':SecretString:password}}' ]]
      DBSubnetGroupName: !Ref DBSubnetGroup
      VPCSecurityGroups:
        - !Ref VPCSecurityGroup
      AllowMajorVersionUpgrade: false
      AutoMinorVersionUpgrade: true
      EngineVersion: "15.6"
      KmsKeyId: !Ref EncryptionKey
      MultiAZ: false
      StorageType: io1
      Iops: 1000
      StorageEncrypted: true
      BackupRetentionPeriod: 0
      DeletionProtection: true
      PubliclyAccessible: false
      Tags:
        - Key: Name
          Value: !Sub "${AWS::StackName}"

  SecretPostgreSQLAttachment1:
    Type: AWS::SecretsManager::SecretTargetAttachment
    Properties:
      SecretId: !Ref RDSSecrets1
      TargetId: !Ref DBInstance1
      TargetType: AWS::RDS::DBInstance

# end Aurora PostgreSQL -----------------------------------------------

# Start Bootstrap Aurora PostgreSQL -----------------------------------
  LambdaBootstrapRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole"
        - "arn:aws:iam::aws:policy/AmazonSageMakerFullAccess"
      Policies:
        - PolicyName: LambdaRDSAccess
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - rds-data:ExecuteStatement
                  - secretsmanager:GetSecretValue
                Resource: '*'
      Description: IAM role to provide needed permission for Lambda function to Bootstrap Aurora PostgreSQL

  LambdaLG:
    Type: AWS::Logs::LogGroup
    DependsOn: LambdaBootstrapFunction
    Properties:
      LogGroupName: !Sub '/aws/lambda/BootstrapAurora-${AWS::StackName}'
      RetentionInDays: 7

  LambdaBootstrapFunction:
    Type: AWS::Lambda::Function
    DependsOn: [ DBNodeWriter ]
    Properties:
      FunctionName: !Sub 'BootstrapAurora-${AWS::StackName}'
      Description: Run SQL Scripts on Aurora PostgreSQL Database using AWS Lambda function
      Handler: index.lambda_handler
      Role: !GetAtt LambdaBootstrapRole.Arn
      Runtime: python3.9
      MemorySize: 2048
      Timeout: 900
      Environment:
        Variables:
          DBSECRET: !Ref RDSSecrets
      Code:
        ZipFile: |
          import cfnresponse
          import psycopg2
          import os
          import boto3
          import json

          def lambda_handler(event, context):
              print (event)
              print (context)
              responseData = {}

              if event['RequestType'] == 'Delete':
                responseData = {'Message': 'SUCCESSFUL'}
                cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData, "CustomResourcePhysicalID")
                return

              try:

                """
                Database Information
                """
                client = boto3.client('secretsmanager', region_name='us-west-2')
                secret_name = os.environ.get('DBSECRET')
                secret_value = client.get_secret_value(SecretId=secret_name)
                secret = json.loads(secret_value['SecretString'])
                uname = secret['username']
                userpwd = secret['password']
                dbname = secret.get('dbname', 'postgres')
                port = secret.get('port', 1521)
                endpoint = secret['host']

                """
                Run sql commands to initialize Product catalog schema in RDS for PostgreSQL
                """

                with psycopg2.connect(user=uname, password=userpwd, database=dbname, port=port, host=endpoint, connect_timeout=60) as dbconn:
                  with dbconn.cursor() as cursor:
                    cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
                    cursor.execute("""CREATE TABLE IF NOT EXISTS dat307bedrockkb (
                                      id  uuid PRIMARY KEY,
                                      embedding vector(1024), chunks text, metadata json
                                );""")
                    cursor.execute("""CREATE INDEX IF NOT EXISTS dat307ind01 ON dat307bedrockkb USING hnsw (embedding vector_cosine_ops) WITH (ef_construction=256);""")
                    dbconn.commit()
                responseData = {'Message': 'SUCCESSFUL!!'}
                cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData, "CustomResourcePhysicalID")
              except Exception as e:
                print('Exception: ' + str(e))
                responseData = {'Message': 'FAILED!!'}
                cfnresponse.send(event, context, cfnresponse.FAILED, responseData, "CustomResourcePhysicalID")
      Layers:
        - !Sub "arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:layer:${Psycopg2LambdaLayerName}"
      VpcConfig:
        SecurityGroupIds:
          - !GetAtt rSG.GroupId
        SubnetIds: [ !Ref Subnet3, !Ref Subnet4 ]

  CustomResoure:
    Type: Custom::DBBootstrap
    Properties:
      ServiceToken: !GetAtt LambdaBootstrapFunction.Arn

  rSG:
    Type: 'AWS::EC2::SecurityGroup'
    Properties:
      GroupDescription: Security group for Lambda which will execute the post database creation steps
      GroupName: post_lambda_sg
      SecurityGroupEgress:
        - CidrIp: 0.0.0.0/0
          Description: Allow all outbound traffic by default
          IpProtocol: '-1'
      VpcId: !Ref VPC

# End Bootstrap Aurora PostgreSQL -------------------------------------


# begin JumpBox         -----------------------------------------------

  EC2InstanceRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${AWS::StackName}-EC2Role"
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore
        - arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM
        - arn:aws:iam::aws:policy/AmazonRDSFullAccess
        - arn:aws:iam::aws:policy/AWSCloudFormationReadOnlyAccess
      Path: "/"
      Policies:
        - PolicyName: !Sub "${AWS::StackName}-EC2PolicyForADRDS"
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - "secretsmanager:GetSecretValue"
                Resource: !Ref RDSSecrets
              - Effect: Allow
                Action:
                  - "secretsmanager:GetSecretValue"
                Resource: !Ref RDSSecrets1                
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
            Action:
              - sts:AssumeRole

  EC2InstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      InstanceProfileName: !Sub "${AWS::StackName}-EC2IProfile"
      Path: /
      Roles:
        - !Ref EC2InstanceRole

  EC2SecurityGroup:
    Type: 'AWS::EC2::SecurityGroup'
    Properties:
      GroupDescription: !Sub "EC2 Bastion Secuirty Group for ${AWS::StackName}"
      GroupName: !Sub '${AWS::StackName}-EC2SecurityGroup'
      VpcId: !Ref VPC
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: '0'
          ToPort: '65535'
          CidrIp: !Ref VpcCIDR
      SecurityGroupEgress:
        - IpProtocol: "-1"
          CidrIp: "0.0.0.0/0"
      Tags:
      - Key: Name
        Value: !Sub '${AWS::StackName}-BastionSecurityGroup'

  EC2Instance:
    Type: AWS::EC2::Instance
    Properties:
      SubnetId: !Ref Subnet1
      InstanceType: t2.medium
      IamInstanceProfile: !Ref EC2InstanceProfile
      ImageId: !Ref AmiID
      SecurityGroupIds:
        - !GetAtt "EC2SecurityGroup.GroupId"

  InstanceSSMDocument:
    Type: AWS::SSM::Document
    Properties:
      DocumentType: Command
      Content:
        schemaVersion: "2.2"
        description: Install necessary libraries
        mainSteps:
        - action: aws:runShellScript
          name: runCommands
          inputs:
            timeoutSeconds: '600'
            runCommand:
            - /usr/bin/sudo /usr/bin/yum -y install git python3 python3-devel python3-psycopg2 python3-pip docker postgresql15 postgresql15-contrib postgresql15-server
            - /usr/bin/pip3 install mysql-connector-python boto3

  EC2Association:
    Type: AWS::SSM::Association
    Properties:
      Name: !Ref InstanceSSMDocument
      Targets:
      - Key: InstanceIds
        Values: [ !Ref EC2Instance ]

# end JumpBox           -----------------------------------------------

# Creating bucket for loading Knowledge Base for Bedrock
  BedrockKB:
    Type: AWS::S3::Bucket

  S3VPCEndpoint:
    Type: 'AWS::EC2::VPCEndpoint'
    Properties:
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Action: '*'
            Effect: Allow
            Resource: '*'
            Principal: '*'
      RouteTableIds:
        - !Ref RouteTable
      ServiceName: !Join
        - ''
        - - com.amazonaws.
          - !Ref 'AWS::Region'
          - .s3
      VpcId: !Ref VPC

# end of S3 Bucket

# Create S3 Loader Workflow
# 1. S3 Bucket put event, invoking Lambda
# 2. Lambda downloading file from S3 Bucket, creating chunks, Generate embeddings using Bedrock LLM, and store in PostgreSQL

  CustomFunctionInvoke:
    Type: AWS::CloudFormation::CustomResource
    DependsOn: BedrockKB
    Version: "1.0"
    Properties:
      ServiceToken: !GetAtt CustomFunctionCopyContentsToS3Bucket.Arn

  CustomFunctionCopyContentsToS3Bucket:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.lambda_handler
      FunctionName: 'copy_apischema_s3'
      Description: "Copies files from the Blog bucket to bucket in this account"
      Timeout: 30
      Role: !GetAtt 'LambdaBasicExecutionRole.Arn'
      Runtime: python3.9
      Environment:
        Variables:
          BUCKET_NAME: !Ref BedrockKB
          PREFIX: "open_api_schema"
      Code:
        ZipFile: |
          import os
          import json
          import boto3
          import logging
          import cfnresponse

          ApiSchema = {
                        "openapi": "3.0.0",
                        "info": {
                            "title": "RDS Management API",
                            "version": "1.0.0",
                            "description": "APIs for managing AWS RDS instances, including checking status, retrieving storage size, increasing volume size, and rolling back to original size."
                        },
                        "paths": {
                            "/check-rds-status": {
                                "get": {
                                    "summary": "Check the status of an RDS instance",
                                    "description": "Check the current status of an RDS instance by its identifier.",
                                    "operationId": "checkRdsStatus",
                                    "parameters": [
                                        {
                                            "name": "db_instance_identifier",
                                            "in": "query",
                                            "description": "The unique identifier of the RDS instance.",
                                            "required": True,
                                            "schema": {
                                                "type": "string"
                                            }
                                        }
                                    ],
                                    "responses": {
                                        "200": {
                                            "description": "Returns the status of the RDS instance.",
                                            "content": {
                                                "application/json": {
                                                    "schema": {
                                                        "type": "object",
                                                        "properties": {
                                                            "body": {
                                                                "type": "string",
                                                                "description": "The status of the RDS instance."
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        },
                                        "400": {
                                            "description": "Bad request. The db_instance_identifier parameter is missing or invalid."
                                        }
                                    }
                                }
                            },
                            "/get-current-storage-size": {
                                "get": {
                                    "summary": "Get the current storage size of an RDS instance",
                                    "description": "Retrieve the current allocated storage size of an RDS instance by its identifier.",
                                    "operationId": "getCurrentStorageSize",
                                    "parameters": [
                                        {
                                            "name": "db_instance_identifier",
                                            "in": "query",
                                            "description": "The unique identifier of the RDS instance.",
                                            "required": True,
                                            "schema": {
                                                "type": "string"
                                            }
                                        }
                                    ],
                                    "responses": {
                                        "200": {
                                            "description": "Returns the current storage size of the RDS instance.",
                                            "content": {
                                                "application/json": {
                                                    "schema": {
                                                        "type": "object",
                                                        "properties": {
                                                            "body": {
                                                                "type": "string",
                                                                "description": "The current storage size of the RDS instance."
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        },
                                        "400": {
                                            "description": "Bad request. The db_instance_identifier parameter is missing or invalid."
                                        }
                                    }
                                }
                            },
                            "/increase-volume-size": {
                                "post": {
                                    "summary": "Increase the storage size of an RDS instance",
                                    "description": "Increase the allocated storage size of an RDS instance by its identifier.",
                                    "operationId": "increaseVolumeSize",
                                    "requestBody": {
                                        "required": True,
                                        "content": {
                                            "application/json": {
                                                "schema": {
                                                    "type": "object",
                                                    "properties": {
                                                        "db_instance_identifier": {
                                                            "type": "string",
                                                            "description": "The unique identifier of the RDS instance."
                                                        },
                                                        "new_storage_size": {
                                                            "type": "integer",
                                                            "description": "The new storage size in GB."
                                                        }
                                                    },
                                                    "required": [
                                                        "db_instance_identifier",
                                                        "new_storage_size"
                                                    ]
                                                }
                                            }
                                        }
                                    },
                                    "responses": {
                                        "200": {
                                            "description": "Initiates the process to increase the volume size of the RDS instance.",
                                            "content": {
                                                "application/json": {
                                                    "schema": {
                                                        "type": "object",
                                                        "properties": {
                                                            "body": {
                                                                "type": "string",
                                                                "description": "Confirmation of the initiated volume size increase."
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        },
                                        "400": {
                                            "description": "Bad request. The db_instance_identifier or new_storage_size parameter is missing or invalid."
                                        }
                                    }
                                }
                            },
                            "/rollback-to-original-size": {
                                "post": {
                                    "summary": "Rollback the storage size of an RDS instance to its original size",
                                    "description": "Rollback the allocated storage size of an RDS instance to its original size.",
                                    "operationId": "rollbackToOriginalSize",
                                    "requestBody": {
                                        "required": True,
                                        "content": {
                                            "application/json": {
                                                "schema": {
                                                    "type": "object",
                                                    "properties": {
                                                        "db_instance_identifier": {
                                                            "type": "string",
                                                            "description": "The unique identifier of the RDS instance."
                                                        },
                                                        "old_storage_size": {
                                                            "type": "integer",
                                                            "description": "The original storage size in GB to rollback to."
                                                        }
                                                    },
                                                    "required": [
                                                        "db_instance_identifier",
                                                        "old_storage_size"
                                                    ]
                                                }
                                            }
                                        }
                                    },
                                    "responses": {
                                        "200": {
                                            "description": "Initiates the process to rollback the volume size of the RDS instance.",
                                            "content": {
                                                "application/json": {
                                                    "schema": {
                                                        "type": "object",
                                                        "properties": {
                                                            "body": {
                                                                "type": "string",
                                                                "description": "Confirmation of the initiated rollback."
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        },
                                        "400": {
                                            "description": "Bad request. The db_instance_identifier or old_storage_size parameter is missing or invalid."
                                        }
                                    }
                                }
                            }
                        }
                    }
          FreeStorageSpace = {
                                "runbookName": "increase-rds-disksize",
                                "description": "Runbook to increase RDS EBS volume size",
                                "cwAlertId": "FreeStorageSpace",
                                "symptoms": "Cloudwatch Alram triggered on CloudWatch Metric FreeStorageSpace due to EBS Volume Free Storage Space is below the threshold"
                                "author": "DBA",
                                "version": "1.0",
                                "lastUpdated": "2023-08-23",
                                "steps": [
                                  {
                                    "stepNumber": 1,
                                    "description": "Step 1 Check if RDS is in avaialble state",
                                    "instructions": [
                                      {
                                        "describe-db-instances": {
                                          "DBInstanceIdentifier": "db_instance_identifier"
                                        },
                                        "return_value": {
                                          "DBInstanceStatus": "available"
                                        }
                                      }
                                    ]
                                  },
                                  {
                                    "stepNumber": 2,
                                    "description": "Step 2 Get the current size",
                                    "instructions": [
                                      {
                                        "describe-db-instances": {
                                          "DBInstanceIdentifier": "db_instance_identifier"
                                        },
                                        "return_value": {
                                          "AllocatedStorage": "?"
                                        }
                                      }
                                    ]
                                  },
                                  {
                                    "stepNumber": 3,
                                    "description": "Step 2 Increase Volume size",
                                    "instructions": [
                                      {
                                        "modify_db_instance": {
                                          "DBInstanceIdentifier": "db_instance_identifier",
                                          "AllocatedStorage": "new_storage_size",
                                          "ApplyImmediately": true
                                        }
                                      }
                                    ]
                                  }
                                ],
                                "rollbackProcedure": [
                                  {
                                    "stepNumber": 1,
                                    "description": "Rollback to original disk size",
                                    "instructions": [
                                      {
                                        "modify_db_instance": {
                                          "DBInstanceIdentifier": "db_instance_identifier",
                                          "AllocatedStorage": "old_storage_size"
                                        }
                                      }
                                    ]
                                  }
                                ],
                                "contactInformation": {
                                  "primaryContact": {
                                    "name": "Primary Contact Name",
                                    "email": "primary.contact@example.com",
                                    "phone": "+1 123 456 7890"
                                  },
                                  "secondaryContact": {
                                    "name": "Secondary Contact Name",
                                    "email": "secondary.contact@example.com",
                                    "phone": "+1 987 654 3210"
                                  }
                                }
                              }

          #copy these two files from s3 to new bucket created by the CloudFormation template
          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def lambda_handler(event, context):
            logger.info('got event {}'.format(event))
            if event['RequestType'] == 'Delete':
              logger.info(f"copy files function called at the time of stack deletion, skipping")
              response = dict(files_copied=0, error=None)
              cfnresponse.send(event, context, cfnresponse.SUCCESS, response)
              return
            try:
              s3 = boto3.client('s3')
              s3.put_object( Body=json.dumps(ApiSchema), Bucket=os.environ.get('BUCKET_NAME'), Key="open_api_schema/ApiSchema.json" )
              s3.put_object( Body=json.dumps(FreeStorageSpace), Bucket=os.environ.get('BUCKET_NAME'), Key="runbooks/FreeStorageSpace.json" )
              response = dict(files_copied=2, error=None)
              cfnresponse.send(event, context, cfnresponse.SUCCESS, response)
            except Exception as e:
              logger.error(e)
              response = dict(files_copied=0, error=str(e))
              cfnresponse.send(event, context, cfnresponse.FAILED, response)
            return 

  BedrockVPCEndpoint:
    Type: 'AWS::EC2::VPCEndpoint'
    Properties:
      VpcEndpointType: 'Interface'
      PrivateDnsEnabled: true
      VpcId: !Ref VPC
      SubnetIds:
        - !Ref Subnet3
        - !Ref Subnet4
      SecurityGroupIds:
        - !GetAtt VPCSecurityGroup.GroupId
        - !GetAtt EC2SecurityGroup.GroupId
      ServiceName: !Join
        - ''
        - - com.amazonaws.
          - !Ref 'AWS::Region'
          - .bedrock

  BedrockRuntimeVPCEndpoint:
    Type: 'AWS::EC2::VPCEndpoint'
    Properties:
      VpcEndpointType: 'Interface'
      PrivateDnsEnabled: true
      VpcId: !Ref VPC
      SubnetIds:
        - !Ref Subnet3
        - !Ref Subnet4
      SecurityGroupIds:
        - !GetAtt VPCSecurityGroup.GroupId
        - !GetAtt EC2SecurityGroup.GroupId
      ServiceName: !Join
        - ''
        - - com.amazonaws.
          - !Ref 'AWS::Region'
          - .bedrock-runtime

  BedrockAgentVPCEndpoint:
    Type: 'AWS::EC2::VPCEndpoint'
    Properties:
      VpcEndpointType: 'Interface'
      PrivateDnsEnabled: true
      VpcId: !Ref VPC
      SubnetIds:
        - !Ref Subnet3
        - !Ref Subnet4
      SecurityGroupIds:
        - !GetAtt VPCSecurityGroup.GroupId
        - !GetAtt EC2SecurityGroup.GroupId
      ServiceName: !Join
        - ''
        - - com.amazonaws.
          - !Ref 'AWS::Region'
          - .bedrock-agent

  BedrockAgentRuntimeVPCEndpoint:
    Type: 'AWS::EC2::VPCEndpoint'
    Properties:
      VpcEndpointType: 'Interface'
      PrivateDnsEnabled: true
      VpcId: !Ref VPC
      SubnetIds:
        - !Ref Subnet3
        - !Ref Subnet4
      SecurityGroupIds:
        - !GetAtt VPCSecurityGroup.GroupId
        - !GetAtt EC2SecurityGroup.GroupId
      ServiceName: !Join
        - ''
        - - com.amazonaws.
          - !Ref 'AWS::Region'
          - .bedrock-agent-runtime

# Bedrock Agent

  BedrockPolicy:
    Type: AWS::IAM::ManagedPolicy
    Properties:
      PolicyDocument:
        Version: '2012-10-17'
        Statement:
          Effect: Allow
          Action: [ bedrock:*, secretsmanager:* ]
          Resource: '*'

  AmazonBedrockExecutionRoleForAgents:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Effect: Allow
          Principal:
            Service: bedrock.amazonaws.com
          Action: sts:AssumeRole
      Path: /
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/AmazonS3FullAccess
        - arn:aws:iam::aws:policy/AWSLambda_FullAccess
        - arn:aws:iam::aws:policy/AmazonBedrockFullAccess
        - arn:aws:iam::aws:policy/AmazonRDSFullAccess
        - arn:aws:iam::aws:policy/AmazonRDSDataFullAccess
        - !Ref BedrockPolicy
      RoleName: !Sub "${AWS::StackName}-AmazonBedrockExecutionRoleForAgents"

  LambdaBasicExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Statement:
        - Effect: Allow
          Principal:
            Service: lambda.amazonaws.com
          Action: sts:AssumeRole
      Path: /
      Policies:
        - PolicyName: S3Access
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - s3:*
                Resource: '*'
        - PolicyName: AWSLambdaBasicExecutionRole
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: arn:aws:logs:*:*:*

  BedrockAgentActionLambda:
    Type: AWS::Lambda::Function
    Properties:
      Handler: index.lambda_handler
      FunctionName: !Sub "${AWS::StackName}_idr_lambda"
      Description: "Contains API calls for iDR for Bedrock Agent"
      Timeout: 600
      Role: !GetAtt 'LambdaBasicExecutionRole.Arn'
      Runtime: python3.9
      Environment:
        Variables:
          DB_IDENTIFIER: !GetAtt DBInstance1.DbiResourceId
      Code:
        ZipFile: |
          import json
          import uuid
          import boto3
          import os

          import logging

          LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")
          lambda_logger = logging.getLogger(__name__)

          if lambda_logger.hasHandlers():
              lambda_logger.setLevel(LOG_LEVEL)
          else:
              logging.basicConfig(level=LOG_LEVEL)

          client = boto3.client('rds')
          db_instance_identifier = os.getenv("DB_IDENTIFIER", "rdspg1")

          def check_rds_status(db_instance_identifier):
              if not db_instance_identifier:
                  return 
              
              response = client.describe_db_instances(
                  DBInstanceIdentifier=db_instance_identifier
              )
              status = response['DBInstances'][0]['DBInstanceStatus']
              if status == 'available':
                  print(f"RDS instance {db_instance_identifier} is available.")
                  return True
              else:
                  print(f"RDS instance {db_instance_identifier} is not available. Current status: {status}")
                  return False

          def get_current_storage_size(db_instance_identifier):
              if not db_instance_identifier:
                  return "Please provide the DBInstanceIdentifier."
              
              response = client.describe_db_instances(
                  DBInstanceIdentifier=db_instance_identifier
              )
              storage_size = response['DBInstances'][0]['AllocatedStorage']
              print(f"Current storage size of RDS instance {db_instance_identifier}: {storage_size} GB")
              return storage_size

          def increase_volume_size(db_instance_identifier, new_storage_size, iops):
              if not db_instance_identifier:
                  return "Please provide the DBInstanceIdentifier."
              
              if not check_rds_status(db_instance_identifier):
                  return(f"RDS instance {db_instance_identifier} is not available. Try again later")

              response = client.modify_db_instance(
                  DBInstanceIdentifier=db_instance_identifier,
                  AllocatedStorage=new_storage_size,
                  Iops=iops,
                  ApplyImmediately=True
              )
              print(f"Started volume size increase for RDS instance {db_instance_identifier}. New storage size: {new_storage_size} GB.")
              return response

          def rollback_to_original_size(db_instance_identifier, old_storage_size):
              if not db_instance_identifier:
                  return "Please provide the DBInstanceIdentifier."
              
              if not check_rds_status(db_instance_identifier):
                  return(f"RDS instance {db_instance_identifier} is not available. Try again later")
              
              response = client.modify_db_instance(
                  DBInstanceIdentifier=db_instance_identifier,
                  AllocatedStorage=old_storage_size,
                  ApplyImmediately=True
              )
              print(f"Rolled back RDS instance {db_instance_identifier} to original storage size: {old_storage_size} GB.")
              return response


          def lambda_handler(event, context):
              # Extract the function to call and parameters from the event
              lambda_logger.info(event)
              function = event.get('function', '')
              lambda_logger.info(f"function to call: {function}")
              
              # Extract parameter values from the event
              parameters = event.get('parameters', [])
              
              for param in parameters:
                  if param['name'] == 'new_storage_size':
                      new_storage_size = int(param['value'])
                  elif param['name'] == 'old_storage_size':
                      old_storage_size = int(param['value'])
                  elif param['name'] == 'iops':
                      iops = int(param['value'])
              

              # Initialize the response body
              responseBody = {}

              if function == 'check_rds_status':
                  if db_instance_identifier:
                      response = check_rds_status(db_instance_identifier)
                      responseBody = {'TEXT': {'body': response}}
                  else:
                      responseBody = {'TEXT': {'body': 'Missing db_instance_identifier parameter'}}

              elif function == 'get_current_storage_size':
                  if db_instance_identifier:
                      response = get_current_storage_size(db_instance_identifier)
                      responseBody = {'TEXT': {'body': response}}
                  else:
                      responseBody = {'TEXT': {'body': 'Missing db_instance_identifier parameter'}}

              elif function == 'increase_volume_size':
                  
                  if db_instance_identifier and new_storage_size:
                      response = increase_volume_size(db_instance_identifier, new_storage_size, iops)
                      responseBody = {'TEXT': {'body': response}}
                  else:
                      responseBody = {'TEXT': {'body': 'Missing db_instance_identifier or new_storage_size parameter'}}

              elif function == 'rollback_to_original_size':
                  
                  if db_instance_identifier and old_storage_size:
                      response = rollback_to_original_size(db_instance_identifier, old_storage_size)
                      responseBody = {'TEXT': {'body': response}}
                  else:
                      responseBody = {'TEXT': {'body': 'Missing db_instance_identifier or old_storage_size parameter'}}

              else:
                  responseBody = {'TEXT': {'body': 'Invalid function name'}}

              # Prepare the action response
              action_response = {
                  'actionGroup': event.get('actionGroup', ''),
                  'function': function,
                  'functionResponse': {
                      'responseBody': responseBody
                  }
              }

              # Prepare the final function response
              function_response = {
                  'response': action_response,
                  'messageVersion': event.get('messageVersion', '')
              }
              print("Response: {}".format(function_response))

              return function_response

  AmazonBedrockAgentKnowledgebase:
    Type: AWS::Bedrock::KnowledgeBase
    DependsOn: [ DBCluster, DBNodeWriter, CustomResoure ]
    Properties:
      Description: Bedrock Agent Knowledgebase for iDR
      KnowledgeBaseConfiguration:
        Type: VECTOR 
        VectorKnowledgeBaseConfiguration:
          EmbeddingModelArn: !Sub "arn:aws:bedrock:${AWS::Region}::foundation-model/amazon.titan-embed-text-v2:0"
          EmbeddingModelConfiguration:
            BedrockEmbeddingModelConfiguration:
              Dimensions: 1024
      Name: !Sub "${AWS::StackName}-agent-kb"
      RoleArn: !GetAtt AmazonBedrockExecutionRoleForAgents.Arn 
      StorageConfiguration: 
        Type: RDS 
        RdsConfiguration:
          ResourceArn: !GetAtt DBCluster.DBClusterArn
          CredentialsSecretArn: !Ref RDSSecrets
          DatabaseName: "postgres"
          TableName: !Sub "${AWS::StackName}bedrockkb"
          FieldMapping: 
              MetadataField: "metadata"
              PrimaryKeyField: "id"
              TextField: "chunks"
              VectorField: "embedding"

  AmazonBedrockAgentDatasource:
    DependsOn: [ DBCluster, DBNodeWriter, CustomResoure ]
    Type: AWS::Bedrock::DataSource
    Properties:
      DataDeletionPolicy: DELETE
      DataSourceConfiguration:
        Type: S3
        S3Configuration: 
          BucketArn: !GetAtt BedrockKB.Arn
          BucketOwnerAccountId: !Sub "${AWS::AccountId}"
          InclusionPrefixes: 
            - runbooks
      Description: "Datasource for Bedrock Agent iDR"
      KnowledgeBaseId: !GetAtt AmazonBedrockAgentKnowledgebase.KnowledgeBaseId
      Name: !Sub "bedrock-ds-${AWS::StackName}"

  AmazonBedrockAgent:
    DependsOn: [ DBCluster, DBNodeWriter, CustomResoure ]
    Type: AWS::Bedrock::Agent
    Properties:
      AgentName: !Sub "${AWS::StackName}-data307-agent"
      ActionGroups:
        - ActionGroupName: !Sub "${AWS::StackName}-idr-agent"
          Description: "iDR Agent"
          ActionGroupExecutor:
            Lambda: !GetAtt BedrockAgentActionLambda.Arn
          ApiSchema:
            S3:
              S3BucketName: !Ref BedrockKB
              S3ObjectKey: "open_api_schema/ApiSchema.json"
      AgentResourceRoleArn: !GetAtt AmazonBedrockExecutionRoleForAgents.Arn 
      Instruction: "You are a database administrator agent, helping in retrieving information about the incidents happenning within Amazon RDS instance and answering question about the incidents and resolving certain incidents."
      AutoPrepare: true
      Description: Bedrock Agent for iDR
      FoundationModel: anthropic.claude-3-5-sonnet-20240620-v1:0
      KnowledgeBases:
        - Description: "Knowledgebase for iDR"
          KnowledgeBaseId: !GetAtt AmazonBedrockAgentKnowledgebase.KnowledgeBaseId
          KnowledgeBaseState: ENABLED


Outputs:

  NotebookInstanceURL:
    Description: SageMaker Notebook Instance URL
    Value: !Join
      - ''
      - - !Sub 'https://console.aws.amazon.com/sagemaker/home?region=${AWS::Region}#/notebook-instances/openNotebook/'
        - !GetAtt NotebookInstance.NotebookInstanceName
        - '?view=classic'

  DBEndpoint:
    Description: 'Aurora PostgreSQL Endpoint'
    Value: !GetAtt 'DBCluster.Endpoint.Address'
    Export:
      Name:
        'Fn::Sub': '${AWS::StackName}-DBEndPoint'

  DBSecret:
    Description: Database Secret
    Value: !Ref RDSSecrets
    Export:
      Name:
        'Fn::Sub': '${AWS::StackName}-DBSecrets'

  AuroraBedrockRole:
    Description: IAM Role for Amazon Aurora and Amazon Bedrock
    Value: !Ref AuroraBedrockRole
    Export:
      Name:
        'Fn::Sub': '${AWS::StackName}-AuroraBedrockRole'

